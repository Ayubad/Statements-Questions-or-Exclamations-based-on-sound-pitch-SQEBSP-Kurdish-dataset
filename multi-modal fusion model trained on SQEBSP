import os
import time
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, random_split
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, classification_report
from sklearn.preprocessing import label_binarize
import itertools
import torchvision.models as models
from torch.nn.utils.rnn import pad_sequence
from PIL import Image
import torchvision.transforms as transforms

# =======================================================
# Directories for processed features
# =======================================================
processed_raw_dir = os.path.normpath("E:/Ayub/Dataset/Extracted_Features")
processed_mfcc_dir = os.path.normpath("E:/Ayub/Dataset/MFCC_Features")
processed_spec_dir = os.path.normpath("E:/Ayub/Dataset/Spectrogram")  #Spectro_Images  CropedImage
labels_list = ["Statements", "Questions", "Exclamations"]

# Default spectrogram shape if file is missing (grayscale image)
DEFAULT_SPEC_SHAPE = (224, 224)

# =======================================================
# Dataset Class with Normalization and Spec Augmentation
# =======================================================
class MultiModalProcessedDataset(Dataset):
    def __init__(self, raw_dir, mfcc_dir, spec_dir, labels_list, augment_spec=True):
        self.raw_dir = os.path.normpath(raw_dir)
        self.mfcc_dir = os.path.normpath(mfcc_dir)
        self.spec_dir = os.path.normpath(spec_dir)
        self.samples = []
        for class_name in os.listdir(self.raw_dir):
            class_path = os.path.join(self.raw_dir, class_name)
            if os.path.isdir(class_path):
                for subfolder in os.listdir(class_path):
                    folder_path = os.path.join(class_path, subfolder)
                    if os.path.isdir(folder_path):
                        for file_name in os.listdir(folder_path):
                            if file_name.endswith('.npy'):
                                rel_path = os.path.join(class_name, subfolder, file_name)
                                self.samples.append((rel_path, class_name))
        self.label2idx = {label: idx for idx, label in enumerate(sorted(labels_list))}
        self.augment_spec = augment_spec
        if self.augment_spec:
            self.spec_augment = transforms.Compose([
                transforms.ToPILImage(),
                transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Lambda(lambda x: x.squeeze(0))  # Convert from (1, H, W) to (H, W)
            ])
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        rel_path, label = self.samples[idx]
        raw_path = os.path.join(self.raw_dir, rel_path)
        mfcc_path = os.path.join(self.mfcc_dir, rel_path)
        spec_path = os.path.join(self.spec_dir, rel_path)
        
        if not os.path.exists(raw_path):
            print("Missing raw file:", raw_path)
            return None
        if not os.path.exists(mfcc_path):
            print("Missing MFCC file:", mfcc_path)
            return None
        
        try:
            raw_feat = torch.tensor(np.load(raw_path), dtype=torch.float32)
            mfcc_feat = torch.tensor(np.load(mfcc_path), dtype=torch.float32)
        except Exception as e:
            print(f"Error loading raw/mfcc for {rel_path}: {e}")
            return None
        
        # Normalize raw features
        raw_feat = (raw_feat - raw_feat.mean()) / (raw_feat.std() + 1e-8)
        # Normalize MFCC features
        mfcc_feat = (mfcc_feat - mfcc_feat.mean()) / (mfcc_feat.std() + 1e-8)
        
        # Process spectrogram features
        if not os.path.exists(spec_path):
            png_spec_path = spec_path[:-4] + ".png"
            if os.path.exists(png_spec_path):
                try:
                    img = Image.open(png_spec_path).convert("L")
                    spec_feat_np = np.array(img)
                except Exception as e:
                    print(f"Error loading spectrogram from {png_spec_path}: {e} - using default zeros")
                    spec_feat = torch.zeros(DEFAULT_SPEC_SHAPE, dtype=torch.float32)
                else:
                    spec_feat = torch.tensor(spec_feat_np, dtype=torch.float32)
            else:
                print("Missing spectrogram file:", spec_path, "- using default zeros")
                spec_feat = torch.zeros(DEFAULT_SPEC_SHAPE, dtype=torch.float32)
        else:
            try:
                spec_feat_np = np.load(spec_path)
            except Exception as e:
                print(f"Error loading spectrogram for {rel_path}: {e} - using default zeros")
                spec_feat = torch.zeros(DEFAULT_SPEC_SHAPE, dtype=torch.float32)
            else:
                if spec_feat_np.ndim == 3 and spec_feat_np.shape[2] == 3:
                    spec_feat_np = spec_feat_np.mean(axis=2)
                spec_feat = torch.tensor(spec_feat_np, dtype=torch.float32)
        
        # Apply spectrogram augmentation if enabled (before normalization)
        if self.augment_spec:
            spec_feat = self.spec_augment(spec_feat)
        
        # Normalize spectrogram features
        spec_feat = (spec_feat - spec_feat.mean()) / (spec_feat.std() + 1e-8)
        
        label_idx = self.label2idx[label]
        label_tensor = torch.tensor(label_idx, dtype=torch.long)
        return raw_feat, mfcc_feat, spec_feat, label_tensor

# =======================================================
# Custom Collate Function with Padding
# =======================================================
def custom_collate(batch):
    batch = [b for b in batch if b is not None]
    if len(batch) == 0:
        return None
    raw_list, mfcc_list, spec_list, label_list = zip(*batch)
    
    padded_raw = pad_sequence(raw_list, batch_first=True)  # [batch, T_max, 768]
    
    H_max = max(t.shape[0] for t in mfcc_list)
    W_max = max(t.shape[1] for t in mfcc_list)
    padded_mfcc = []
    for t in mfcc_list:
        pad_H = H_max - t.shape[0]
        pad_W = W_max - t.shape[1]
        t_padded = torch.nn.functional.pad(t, (0, pad_W, 0, pad_H), mode='constant', value=0)
        padded_mfcc.append(t_padded)
    padded_mfcc = torch.stack(padded_mfcc)  # [batch, H_max, W_max]
    
    H_max_spec = max(t.shape[0] for t in spec_list)
    W_max_spec = max(t.shape[1] for t in spec_list)
    padded_spec = []
    for t in spec_list:
        pad_H = H_max_spec - t.shape[0]
        pad_W = W_max_spec - t.shape[1]
        t_padded = torch.nn.functional.pad(t, (0, pad_W, 0, pad_H), mode='constant', value=0)
        padded_spec.append(t_padded)
    padded_spec = torch.stack(padded_spec)  # [batch, H_max_spec, W_max_spec]
    
    labels_tensor = torch.tensor(label_list, dtype=torch.long)
    return padded_raw, padded_mfcc, padded_spec, labels_tensor

# =======================================================
# Create Dataset and DataLoaders
# =======================================================
# Note: For demonstration the same dataset instance (with augmentation) is used.
# In practice, you might want to disable augmentation for validation.
full_dataset = MultiModalProcessedDataset(processed_raw_dir, processed_mfcc_dir, processed_spec_dir, labels_list, augment_spec=True)
print("Total samples in dataset:", len(full_dataset))
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
print("Train samples:", len(train_dataset), "Validation samples:", len(val_dataset))
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate)

# Debug: Find first valid sample.
sample = None
for i in range(len(train_dataset)):
    sample = train_dataset[i]
    if sample is not None:
        break
if sample is not None:
    print("Raw feature shape:", sample[0].shape, "sum:", sample[0].sum().item())
    print("MFCC feature shape:", sample[1].shape, "sum:", sample[1].sum().item())
    print("Spectrogram shape:", sample[2].shape, "sum:", sample[2].sum().item())
else:
    print("No valid sample found in training dataset.")

# =======================================================
# Model Definition with Updated Normalization and Regularization
# =======================================================
class RawAudioBranch(nn.Module):
    def __init__(self, input_dim=768, output_dim=128):
        super(RawAudioBranch, self).__init__()
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.bn = nn.BatchNorm1d(input_dim)  # Using BatchNorm1d instead of LayerNorm
        self.fc = nn.Linear(input_dim, output_dim)
    
    def forward(self, x):
        # x: [batch, T, 768] -> transpose to [batch, 768, T]
        x = x.transpose(1, 2)
        x = self.pool(x)      # [batch, 768, 1]
        x = x.squeeze(-1)     # [batch, 768]
        x = self.bn(x)
        return self.fc(x)

class MFCCBranch(nn.Module):
    def __init__(self, output_dim=128):
        super(MFCCBranch, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.adapool = nn.AdaptiveAvgPool2d((4, 4))
        # Add LayerNorm before FC
        self.fc = nn.Sequential(
            nn.LayerNorm(64 * 4 * 4),
            nn.Linear(64 * 4 * 4, output_dim)
        )
    
    def forward(self, x):
        x = x.unsqueeze(1)  # [batch, 1, H, W]
        x = self.conv_layers(x)
        x = self.adapool(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)

class SpectrogramBranch(nn.Module):
    def __init__(self, output_dim=128):
        super(SpectrogramBranch, self).__init__()
        self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, output_dim)
    
    def forward(self, x):
        if x.dim() == 2:
            x = x.unsqueeze(0)
        if x.dim() == 3:
            x = x.unsqueeze(1)  # [batch, 1, H, W]
        if x.size(1) == 1:
            x = x.repeat(1, 3, 1, 1)
        return self.resnet(x)

class MultiModalFusionModel(nn.Module):
    def __init__(self, num_classes=3):
        super(MultiModalFusionModel, self).__init__()
        self.raw_branch = RawAudioBranch(input_dim=768, output_dim=128)
        self.mfcc_branch = MFCCBranch(output_dim=128)
        self.spec_branch = SpectrogramBranch(output_dim=128)
        self.fusion_fc = nn.Sequential(
            nn.Linear(128 * 3, 256),
            nn.ReLU(),
            nn.Dropout(0.5),  # Increased dropout
            nn.Linear(256, num_classes)
        )
    
    def forward(self, raw_input, mfcc_input, spec_input):
        feat_raw = self.raw_branch(raw_input)    # [batch, 128]
        feat_mfcc = self.mfcc_branch(mfcc_input)   # [batch, 128]
        feat_spec = self.spec_branch(spec_input)   # [batch, 128]
        fused = torch.cat([feat_raw, feat_mfcc, feat_spec], dim=1)  # [batch, 384]
        return self.fusion_fc(fused)

# =======================================================
# Training Setup with Aggressive LR Reduction
# =======================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = MultiModalFusionModel().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=5e-3)  # Lower LR, higher weight decay
num_epochs = 30
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)

train_losses = []
train_accuracies = []
val_losses = []
val_accuracies = []

# =======================================================
# Training Loop with Validation
# =======================================================
start_time = time.time()

try:
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        model.train()
        running_loss = 0.0
        correct_preds = 0
        total_preds = 0
        for batch in train_loader:
            if batch is None:
                continue
            raw_feat, mfcc_feat, spec_feat, labels = [b.to(device) for b in batch]
            optimizer.zero_grad()
            outputs = model(raw_feat, mfcc_feat, spec_feat)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            correct_preds += (predicted == labels).sum().item()
            total_preds += labels.size(0)
        train_loss = running_loss / total_preds if total_preds > 0 else 0
        train_acc = 100 * correct_preds / total_preds if total_preds > 0 else 0
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        
        model.eval()
        val_running_loss = 0.0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for batch in val_loader:
                if batch is None:
                    continue
                raw_feat, mfcc_feat, spec_feat, labels = [b.to(device) for b in batch]
                outputs = model(raw_feat, mfcc_feat, spec_feat)
                loss = criterion(outputs, labels)
                val_running_loss += loss.item() * labels.size(0)
                _, predicted = torch.max(outputs, 1)
                val_correct += (predicted == labels).sum().item()
                val_total += labels.size(0)
        val_loss = val_running_loss / val_total if val_total > 0 else 0
        val_acc = 100 * val_correct / val_total if val_total > 0 else 0
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)
        
        scheduler.step(val_loss)
        
        epoch_duration = time.time() - epoch_start_time
        print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, " +
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        print("Current learning rate:", scheduler.get_last_lr())
except KeyboardInterrupt:
    print("Training interrupted.")
    
total_training_time = time.time() - start_time
print(f"Total training time: {total_training_time:.2f} seconds ({total_training_time / 60:.2f} minutes)")

# =======================================================
# Plot Training/Validation Curves
# =======================================================
epochs_range = range(1, len(train_losses)+1)
plt.figure(figsize=(12,5))
plt.title('Statements, Questions, and Exclamations Classification')
plt.subplot(1,2,1)
plt.plot(epochs_range, train_losses, 'b-', label='Train Loss')
plt.plot(epochs_range, val_losses, 'r-', label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Curve')
plt.legend()

plt.subplot(1,2,2)
plt.plot(epochs_range, train_accuracies, 'b-', label='Train Acc')
plt.plot(epochs_range, val_accuracies, 'r-', label='Val Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy Curve')
plt.legend()
plt.show()

# =======================================================
# Evaluation: Confusion Matrix, ROC, and Classification Metrics
# =======================================================
model.eval()
all_labels = []
all_preds = []
all_probs = []

with torch.no_grad():
    for batch in val_loader:
        if batch is None:
            continue
        raw_feat, mfcc_feat, spec_feat, labels = [b.to(device) for b in batch]
        outputs = model(raw_feat, mfcc_feat, spec_feat)
        probs = nn.functional.softmax(outputs, dim=1)
        _, predicted = torch.max(outputs, 1)
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(predicted.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
if cm.size == 0:
    print("Confusion matrix is empty, skipping plot.")
else:
    plt.figure(figsize=(6,5))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.colorbar()
    tick_marks = np.arange(len(labels_list))
    plt.xticks(tick_marks, labels_list, rotation=45)
    plt.yticks(tick_marks, labels_list)
    fmt = 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()
    plt.show()

# ROC Curves
if len(all_labels) == 0:
    print("No validation samples available for ROC computation, skipping ROC plot.")
else:
    all_labels_binarized = label_binarize(all_labels, classes=range(len(labels_list)))
    n_classes = all_labels_binarized.shape[1]
    fpr = {}
    tpr = {}
    roc_auc = {}
    all_probs = np.array(all_probs)
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(all_labels_binarized[:, i], all_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])
    fpr["micro"], tpr["micro"], _ = roc_curve(all_labels_binarized.ravel(), all_probs.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
    plt.figure(figsize=(8,6))
    plt.plot(fpr["micro"], tpr["micro"],
             label='micro-average ROC (area = {0:0.2f})'.format(roc_auc["micro"]),
             color='deeppink', linestyle=':', linewidth=4)
    colors = ['aqua', 'darkorange', 'cornflowerblue']
    for i, color in zip(range(n_classes), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=2,
                 label='ROC of class {0} (area = {1:0.2f})'.format(labels_list[i], roc_auc[i]))
    plt.plot([0, 1], [0, 1], 'k--', lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves')
    plt.legend(loc="lower right")
    plt.show()

# Classification Metrics
precision = precision_score(all_labels, all_preds, average='macro')
recall = recall_score(all_labels, all_preds, average='macro')
f1 = f1_score(all_labels, all_preds, average='macro')
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=labels_list))
